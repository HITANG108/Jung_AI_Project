import streamlit as st
import os
import sys

# ==========================================
# 1. åŸºç¡€é…ç½®ä¸é¡µé¢è®¾ç½®
# ==========================================
st.set_page_config(page_title="è£æ ¼è§£æ¢¦å®¤", page_icon="ğŸ•¯ï¸")
st.title("ğŸ•¯ï¸ å¡å°”Â·è£æ ¼çš„ç§äººè¯Šå®¤")
st.markdown("### *â€œå‘å¤–çœ‹çš„äººåœ¨åšæ¢¦ï¼Œå‘å†…çœ‹çš„äººæ˜¯æ¸…é†’çš„ã€‚â€*")

# ä¾§è¾¹æ ï¼šæ”¾ä¸€äº›è¯´æ˜
with st.sidebar:
    st.header("å…³äº")
    st.write("è¿™æ˜¯ä¸€ä¸ªåŸºäº RAG æŠ€æœ¯çš„ AI è£æ ¼ã€‚")
    st.write("å®ƒé˜…è¯»äº†è‹±æ–‡ç‰ˆã€ŠäººåŠå…¶è±¡å¾ã€‹ï¼Œå¹¶ç”¨ä¸­æ–‡ä¸ºä½ è§£æƒ‘ã€‚")
    st.write("---")
    st.info("æç¤ºï¼šä½ å¯ä»¥é—®å…³äºæ¢¦çš„è±¡å¾ï¼Œæˆ–è€…ä¹¦ä¸­çš„æ¦‚å¿µã€‚")

# ==========================================
# 2. æ ¸å¿ƒé€»è¾‘ï¼ˆåªåŠ è½½ä¸€æ¬¡ï¼Œæé«˜é€Ÿåº¦ï¼‰
# ==========================================
@st.cache_resource
def load_jung_brain():
    """
    è¿™ä¸ªå‡½æ•°è´Ÿè´£åˆå§‹åŒ– AI å’Œæ•°æ®åº“ã€‚
    åŠ äº† @st.cache_resource åï¼Œå®ƒåªä¼šè¿è¡Œä¸€æ¬¡ï¼Œ
    ä¸ä¼šæ¯æ¬¡ä½ å‘æ¶ˆæ¯éƒ½é‡æ–°åŠ è½½æ¨¡å‹ã€‚
    """
    # --- è¿™é‡Œå¡«å…¥ä½ çš„é…ç½® ---
    MY_API_KEY = "sk-6CqRNrrPMboZ8tqVbvAZ8wkCV0Wcf3jvpTBJ3hTRvneOnK80" 
    MY_BASE_URL = "https://api.moonshot.cn/v1" # Kimi åœ°å€
    BOOK_PATH = "./data/Man and His Symbols.txt"
    # -----------------------

    os.environ["OPENAI_API_KEY"] = MY_API_KEY
    os.environ["OPENAI_API_BASE"] = MY_BASE_URL

    # å¯¼å…¥åº“
    from langchain_community.document_loaders import TextLoader
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    from langchain_huggingface import HuggingFaceEmbeddings
    from langchain_community.vectorstores import Chroma
    from langchain_openai import ChatOpenAI
    from langchain.chains import create_retrieval_chain
    from langchain.chains.combine_documents import create_stuff_documents_chain
    from langchain_core.prompts import ChatPromptTemplate

    # 1. åŠ è½½æ•°æ®
    if not os.path.exists(BOOK_PATH):
        st.error(f"æ‰¾ä¸åˆ°æ–‡ä»¶ï¼š{BOOK_PATH}")
        return None

    loader = TextLoader(BOOK_PATH, encoding='utf-8') # å¦‚æœæŠ¥é”™æ”¹ä¸º autodetect_encoding=True
    docs = loader.load()
    
    # 2. åˆ‡ç‰‡
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    splits = text_splitter.split_documents(docs)

    # 3. å‘é‡åŒ– (æœ¬åœ°æ¨¡å‹)
    embedding_model = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
    vectorstore = Chroma.from_documents(documents=splits, embedding=embedding_model)
    retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

    # 4. å¤§æ¨¡å‹ (Kimi)
    llm = ChatOpenAI(
        model="moonshot-v1-8k", 
        temperature=0.7,
        api_key=MY_API_KEY,
        base_url=MY_BASE_URL
    )

    # 5. æç¤ºè¯
    system_prompt = (
        "ä½ ç°åœ¨æ˜¯å¿ƒç†å­¦å®¶å¡å°”Â·è£æ ¼ã€‚ä½ é¢å‰åç€ä¸€ä½å¯»æ±‚æŒ‡å¼•çš„æœ‹å‹ã€‚"
        "è¯·æ ¹æ®ã€èƒŒæ™¯çŸ¥è¯†ã€‘ï¼ˆã€ŠäººåŠå…¶è±¡å¾ã€‹ï¼‰å›ç­”é—®é¢˜ï¼Œå¿…é¡»ç”¨**ä¸­æ–‡**ã€‚"
        "é£æ ¼è¦æ±‚ï¼šæ·±é‚ƒã€æ¸©æš–ã€å¯Œæœ‰å“²ç†ï¼Œåƒä¸€ä½æ™ºè€…ã€‚"
        "\n\nã€èƒŒæ™¯çŸ¥è¯†ã€‘:\n{context}"
    )
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", "{input}"),
    ])

    chain = create_retrieval_chain(retriever, create_stuff_documents_chain(llm, prompt))
    return chain

# åŠ è½½è£æ ¼å¤§è„‘ï¼ˆå¦‚æœæ˜¾ç¤º Spinner è¯´æ˜æ­£åœ¨åŠ è½½ï¼‰
with st.spinner("è£æ ¼åŒ»å¸ˆæ­£åœ¨æ•´ç†ç¬”è®°...ï¼ˆåˆæ¬¡è¿è¡Œå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰"):
    chain = load_jung_brain()

if chain is None:
    st.stop() # å¦‚æœåŠ è½½å¤±è´¥å°±åœæ­¢

# ==========================================
# 3. èŠå¤©ç•Œé¢é€»è¾‘
# ==========================================

# åˆå§‹åŒ–èŠå¤©è®°å½•ï¼ˆSession Stateï¼‰
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "ä½ å¥½ï¼Œæˆ‘æ˜¯è£æ ¼ã€‚è¯·å‘Šè¯‰æˆ‘ä½ çš„æ¢¦ï¼Œæˆ–è€…ä½ å¿ƒä¸­çš„å›°æƒ‘ã€‚"}
    ]

# æ˜¾ç¤ºå†å²æ¶ˆæ¯
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# å¤„ç†ç”¨æˆ·è¾“å…¥
if user_input := st.chat_input("åœ¨è¿™é‡Œè¾“å…¥ä½ çš„æ¢¦..."):
    # 1. æ˜¾ç¤ºç”¨æˆ·çš„è¯
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # 2. ç”Ÿæˆå›å¤
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        message_placeholder.markdown("Thinking...") # æ€è€ƒæ—¶çš„å ä½ç¬¦
        
        # è°ƒç”¨ RAG é“¾
        response = chain.invoke({"input": user_input})
        answer = response['answer']
        
        # æ˜¾ç¤ºç»“æœ
        message_placeholder.markdown(answer)
    
    # 3. ä¿å­˜å›å¤åˆ°å†å²
    st.session_state.messages.append({"role": "assistant", "content": answer})